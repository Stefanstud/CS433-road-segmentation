{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# autoreload\n",
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "if os.getcwd().split('/')[-1] != 'Road-Segmentation-ML':\n",
                "    os.chdir(\"..\")\n",
                "print(\"CWD:\", os.getcwd())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torchvision.transforms as transforms\n",
                "from datasets.BaseDataset import BaseDataset\n",
                "from datasets.TransformDataset import TransformDataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# paths to image and ground truth folders\n",
                "image_folder = \"datasets/train/images/\"\n",
                "gt_folder = \"datasets/train/groundtruth/\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create an instance of the base dataset class\n",
                "dataset = BaseDataset(image_folder, gt_folder)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# seed for reproducibility\n",
                "torch.manual_seed(0)\n",
                "# split the dataset into training and validation sets\n",
                "train_set, val_set = torch.utils.data.random_split(\n",
                "    dataset, [int(0.8 * len(dataset)), int(0.2 * len(dataset))]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# define data transform (same for images and groundtruth)\n",
                "transform = transforms.Compose(\n",
                "    [\n",
                "        # transforms.Resize((400, 400)), # crashes with 400 x 400\n",
                "        transforms.ToTensor(),\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# transforms\n",
                "train_set = TransformDataset(\n",
                "    train_set, image_transform=transform, gt_transform=transform\n",
                ")\n",
                "val_set = TransformDataset(val_set, image_transform=transform, gt_transform=transform)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# define batch size\n",
                "batch_size = 2\n",
                "# create data loaders\n",
                "train_loader = torch.utils.data.DataLoader(\n",
                "    train_set, batch_size=batch_size, shuffle=True\n",
                ")\n",
                "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# define model\n",
                "# model = timm.create_model('unet', pretrained=False)\n",
                "model = torch.hub.load(\n",
                "    \"milesial/Pytorch-UNet\", \"unet_carvana\", pretrained=False, scale=0.5\n",
                ")\n",
                "# model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# define loss function\n",
                "criterion = torch.nn.BCEWithLogitsLoss()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# define Adam optimizer\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
                "# define SGD optimizer\n",
                "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# number of epochs to train the model\n",
                "n_epochs = 10\n",
                "# device to use for training\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "model.to(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# training loop\n",
                "for epoch in range(n_epochs):\n",
                "    model.train()\n",
                "    running_loss = 0.0\n",
                "    for inputs, labels in train_loader:\n",
                "        inputs, labels = inputs.to(device), labels.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(inputs)\n",
                "        # take one channel of the output\n",
                "        # outputs = outputs[:, [0], :, :]\n",
                "        loss = criterion(outputs, labels.float())\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        running_loss += loss.item()\n",
                "    print(\"Epoch: %d | Loss: %.4f\" % (epoch, running_loss / len(train_loader)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# validation loop\n",
                "model.eval()\n",
                "running_loss = 0.0\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in val_loader:\n",
                "        inputs, labels = inputs.to(device), labels.to(device)\n",
                "        outputs = model(inputs)\n",
                "        # take one channel of the output\n",
                "        outputs = outputs[:, [0], :, :]\n",
                "        loss = criterion(outputs, labels.float())\n",
                "        running_loss += loss.item()\n",
                "    # print loss\n",
                "    print(\"Validation loss: %.4f\" % (running_loss / len(val_loader)))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
