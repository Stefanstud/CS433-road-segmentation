{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from train_utils import prepare_data, prepare_model, prepare_optimizer, train, set_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds\n",
    "set_seeds()\n",
    "\n",
    "# create folder models if it doesn't exist\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = OmegaConf.create(\n",
    "    dict(\n",
    "        # General\n",
    "        seed=0,\n",
    "        # Data folders\n",
    "        image_folder=\"datasets/train/images/\",\n",
    "        gt_folder=\"datasets/train/groundtruth/\",\n",
    "        # Data tranforms\n",
    "        # random_resized_crop: crop a random portion of image and resize it to a given size\n",
    "        random_resized_crop=False,\n",
    "        output_size=(400, 400),  # expected output size of the crop, for each edge.\n",
    "        random_resized_crop_scale=(0.5, 1.0),\n",
    "        # random_horizontal_flip: randomly flip the image horizontally with a given probability\n",
    "        random_horizontal_flip=False,\n",
    "        # random_vertical_flip: randomly flip the image vertically with a given probability\n",
    "        random_vertical_flip=False,\n",
    "        # random_rotation: randomly rotate the image with a given probability\n",
    "        random_rotation=False,\n",
    "        degrees=10,  # range of degrees to select from\n",
    "        # color_jitter: randomly change the brightness, contrast and saturation of an image\n",
    "        color_jitter=False,\n",
    "        brightness=0.1,  # how much to jitter brightness.\n",
    "        contrast=0.1,  # how much to jitter contrast.\n",
    "        saturation=0.1,  # how much to jitter saturation.\n",
    "        hue=0.1,  # how much to jitter hue.\n",
    "        # normalization\n",
    "        normalization=True,  # TODO: Should it always be True?\n",
    "        # Data loaders\n",
    "        batch_size=2,\n",
    "        train_size=0.8,\n",
    "        val_size=0.1,\n",
    "        test_size=0.1,\n",
    "        # Model\n",
    "        # UNetV2\n",
    "        model_name=\"UNetV2\",\n",
    "        model_in_channels=3,\n",
    "        model_out_channels=1,\n",
    "        model_init_features=32,\n",
    "        model_pretrained=False,\n",
    "        model_save_name=\"models/checkpoints/unetv2-1.pt\",\n",
    "        # Optimizer\n",
    "        optim_name=\"adam\",  # sgd\n",
    "        optim_lr=0.1,\n",
    "        optim_momentum=0.9,  # TODO: Try with (optim_momentum != 0) and without (momentum = 0)?\n",
    "        # Training\n",
    "        n_steps=2000,\n",
    "        eval_freq=100,\n",
    "        # Wandb logging\n",
    "        wandb_project=\"road-segmentation\",\n",
    "        wandb_run=\"unet-v2\",\n",
    "        entity=\"feeit\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ToTensor.\n",
      "Using Normalize with mean=(0.5, 0.5, 0.5) and std=(0.5, 0.5, 0.5).\n"
     ]
    }
   ],
   "source": [
    "# prepare train, validation and test loaders\n",
    "train_loader, val_loader, test_loader = prepare_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing UNetV2 model with in_channels=3, out_channels=1, init_features=32, pretrained=False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/stef/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    }
   ],
   "source": [
    "# prepare model\n",
    "model = prepare_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing SGD optimizer with lr=0.1, momentum=0.9.\n"
     ]
    }
   ],
   "source": [
    "# prepare optimizer\n",
    "optimizer = prepare_optimizer(model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetV2(\n",
       "  (model): UNet(\n",
       "    (encoder1): Sequential(\n",
       "      (enc1conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (enc1norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (enc1relu1): ReLU(inplace=True)\n",
       "      (enc1conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (enc1norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (enc1relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (encoder2): Sequential(\n",
       "      (enc2conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (enc2norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (enc2relu1): ReLU(inplace=True)\n",
       "      (enc2conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (enc2norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (enc2relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (encoder3): Sequential(\n",
       "      (enc3conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (enc3norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (enc3relu1): ReLU(inplace=True)\n",
       "      (enc3conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (enc3norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (enc3relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (encoder4): Sequential(\n",
       "      (enc4conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (enc4norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (enc4relu1): ReLU(inplace=True)\n",
       "      (enc4conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (enc4norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (enc4relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (bottleneck): Sequential(\n",
       "      (bottleneckconv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bottlenecknorm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneckrelu1): ReLU(inplace=True)\n",
       "      (bottleneckconv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bottlenecknorm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneckrelu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (upconv4): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (decoder4): Sequential(\n",
       "      (dec4conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dec4norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dec4relu1): ReLU(inplace=True)\n",
       "      (dec4conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dec4norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dec4relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (upconv3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (decoder3): Sequential(\n",
       "      (dec3conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dec3norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dec3relu1): ReLU(inplace=True)\n",
       "      (dec3conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dec3norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dec3relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (upconv2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (decoder2): Sequential(\n",
       "      (dec2conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dec2norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dec2relu1): ReLU(inplace=True)\n",
       "      (dec2conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dec2norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dec2relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (upconv1): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (decoder1): Sequential(\n",
       "      (dec1conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dec1norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dec1relu1): ReLU(inplace=True)\n",
       "      (dec1conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dec1norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dec1relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device to use for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstefan-krsteski\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/stef/Desktop/School/EPFL/CS-433 Machine Learning/ML_course/projects/Road-Segmentation-ML/wandb/run-20231122_180425-11m6tdxy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/stefan-krsteski/road-segmentation/runs/11m6tdxy' target=\"_blank\">unet-v2</a></strong> to <a href='https://wandb.ai/stefan-krsteski/road-segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/stefan-krsteski/road-segmentation' target=\"_blank\">https://wandb.ai/stefan-krsteski/road-segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/stefan-krsteski/road-segmentation/runs/11m6tdxy' target=\"_blank\">https://wandb.ai/stefan-krsteski/road-segmentation/runs/11m6tdxy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at step:  0\n",
      "Best model saved at step:  100\n",
      "Best model saved at step:  200\n",
      "Best model saved at step:  300\n",
      "Best model saved at step:  400\n",
      "Best model saved at step:  500\n",
      "Best model saved at step:  600\n",
      "Best model saved at step:  700\n",
      "Best model saved at step:  800\n",
      "Best model saved at step:  900\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/stef/Desktop/School/EPFL/CS-433 Machine Learning/ML_course/projects/Road-Segmentation-ML/notebooks/unet-v2.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stef/Desktop/School/EPFL/CS-433%20Machine%20Learning/ML_course/projects/Road-Segmentation-ML/notebooks/unet-v2.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/stef/Desktop/School/EPFL/CS-433%20Machine%20Learning/ML_course/projects/Road-Segmentation-ML/notebooks/unet-v2.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m trained_model \u001b[39m=\u001b[39m train(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stef/Desktop/School/EPFL/CS-433%20Machine%20Learning/ML_course/projects/Road-Segmentation-ML/notebooks/unet-v2.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model, device, train_loader, val_loader, criterion, optimizer, args\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stef/Desktop/School/EPFL/CS-433%20Machine%20Learning/ML_course/projects/Road-Segmentation-ML/notebooks/unet-v2.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/School/EPFL/CS-433 Machine Learning/ML_course/projects/Road-Segmentation-ML/train_utils.py:216\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, val_loader, criterion, optimizer, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    215\u001b[0m \u001b[39m# logging\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m wandb\u001b[39m.\u001b[39mlog({\u001b[39m\"\u001b[39m\u001b[39mTraining Loss\u001b[39m\u001b[39m\"\u001b[39m: loss\u001b[39m.\u001b[39;49mitem()}, step\u001b[39m=\u001b[39mstep)\n\u001b[1;32m    217\u001b[0m train_pixel_accuracy, train_iou, train_dice \u001b[39m=\u001b[39m calculate_metrics(outputs, labels)\n\u001b[1;32m    218\u001b[0m wandb\u001b[39m.\u001b[39mlog(\n\u001b[1;32m    219\u001b[0m     {\n\u001b[1;32m    220\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTraining Pixel Accuracy\u001b[39m\u001b[39m\"\u001b[39m: train_pixel_accuracy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m     step\u001b[39m=\u001b[39mstep,\n\u001b[1;32m    225\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "trained_model = train(\n",
    "    model, device, train_loader, val_loader, criterion, optimizer, args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transforms\n",
    "from torchvision import transforms\n",
    "from datasets.TestDataset import TestDataset\n",
    "from models.UNetV2 import UNetV2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from examples.mask_to_submission import *\n",
    "import torchvision.models.segmentation as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select checkpoint\n",
    "MODEL = \"models/checkpoints/unetv2-1.pt\"\n",
    "\n",
    "model = UNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint\n",
    "checkpoint = torch.load(MODEL)\n",
    "\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the test folder\n",
    "test_folder = \"datasets/test/\"\n",
    "\n",
    "# define transformations\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# create test dataset\n",
    "test_dataset = TestDataset(test_folder, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO FIX THIS, bad predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "prediction_filenames = []\n",
    "for i in range(len(test_dataset)):\n",
    "    # get image\n",
    "    image = test_dataset[i]\n",
    "    # create prediction\n",
    "    prediction = model(image.unsqueeze(0))\n",
    "    # threshold prediction\n",
    "    prediction = (prediction > 0.5).float()\n",
    "    # save prediction\n",
    "    prediction_filename = \"predictions/prediction_\" + str(i + 1) + \".png\"\n",
    "    prediction_filenames.append(prediction_filename)\n",
    "    plt.imsave(prediction_filename, prediction.squeeze().detach().numpy(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission\n",
    "masks_to_submission(\"submission.csv\", *prediction_filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
