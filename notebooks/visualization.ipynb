{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from datasets.TransformDataset import TransformDataset\n",
    "from datasets.BaseDataset import BaseDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select checkpoint\n",
    "MODEL = \"models/unet-v1.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/stef/.cache/torch/hub/milesial_Pytorch-UNet_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load checkpoint\n",
    "checkpoint = torch.load(MODEL)\n",
    "# create model\n",
    "model = torch.hub.load(\n",
    "    \"milesial/Pytorch-UNet\", \"unet_carvana\", pretrained=False, scale=0.5\n",
    ")\n",
    "# model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=False)\n",
    "# load model weights\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to image and ground truth folders\n",
    "image_folder = \"datasets/train/images/\"\n",
    "gt_folder = \"datasets/train/groundtruth/\"\n",
    "\n",
    "dataset = BaseDataset(image_folder, gt_folder)\n",
    "\n",
    "# split the dataset into training and validation sets\n",
    "train_set, val_set = torch.utils.data.random_split(\n",
    "    dataset, [int(0.8 * len(dataset)), int(0.2 * len(dataset))]\n",
    ")\n",
    "\n",
    "# define data transform (same for images and groundtruth)\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((400, 400)),  # crashes with 400 x 400\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "# transforms\n",
    "train_set = TransformDataset(\n",
    "    train_set, image_transform=transform, gt_transform=transform\n",
    ")\n",
    "val_set = TransformDataset(val_set, image_transform=transform, gt_transform=transform)\n",
    "\n",
    "# define batch size\n",
    "batch_size = 2\n",
    "\n",
    "# create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIX THIS!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PngImageFile' object has no attribute 'unsqueeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/stef/Desktop/School/EPFL/CS-433 Machine Learning/ML_course/projects/Road-Segmentation-ML/notebooks/visualization.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stef/Desktop/School/EPFL/CS-433%20Machine%20Learning/ML_course/projects/Road-Segmentation-ML/notebooks/visualization.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m gt \u001b[39m=\u001b[39m dataset[K][\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stef/Desktop/School/EPFL/CS-433%20Machine%20Learning/ML_course/projects/Road-Segmentation-ML/notebooks/visualization.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# predict\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/stef/Desktop/School/EPFL/CS-433%20Machine%20Learning/ML_course/projects/Road-Segmentation-ML/notebooks/visualization.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pred \u001b[39m=\u001b[39m model(image\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stef/Desktop/School/EPFL/CS-433%20Machine%20Learning/ML_course/projects/Road-Segmentation-ML/notebooks/visualization.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(pred\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stef/Desktop/School/EPFL/CS-433%20Machine%20Learning/ML_course/projects/Road-Segmentation-ML/notebooks/visualization.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# convert to numpy array\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PngImageFile' object has no attribute 'unsqueeze'"
     ]
    }
   ],
   "source": [
    "for K in range(10):\n",
    "    # get image and ground truth\n",
    "    image = transform(dataset[K][0])\n",
    "    gt = transform(dataset[K][1])\n",
    "    # predict\n",
    "    pred = model(image.unsqueeze(0))\n",
    "    print(pred.shape)\n",
    "    # convert to numpy array\n",
    "    image = image.numpy().transpose(1, 2, 0)\n",
    "    gt = gt.numpy().squeeze(0)\n",
    "\n",
    "    # for mateuszbuda [1, 1, 400, 400]\n",
    "    # pred = pred.detach().numpy().squeeze(0).squeeze(0)\n",
    "\n",
    "    # for milesial [1, 2, 400, 400]\n",
    "    pred = pred[:, [0], :, :]\n",
    "    pred = pred.detach().numpy().squeeze(0).squeeze(0)\n",
    "\n",
    "    # threshold\n",
    "    pred[pred <= 0.5] = 0\n",
    "    pred[pred > 0.5] = 1\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(9, 3))\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title(\"Image\")\n",
    "    ax[1].imshow(gt)\n",
    "    ax[1].set_title(\"Ground Truth\")\n",
    "    ax[2].imshow(pred)\n",
    "    ax[2].set_title(\"Prediction\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
