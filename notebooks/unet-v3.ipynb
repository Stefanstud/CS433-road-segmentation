{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 40,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "The autoreload extension is already loaded. To reload it, use:\n",
                  "  %reload_ext autoreload\n"
               ]
            }
         ],
         "source": [
            "# autoreload\n",
            "\n",
            "%load_ext autoreload\n",
            "%autoreload 2"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 41,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "CWD: /home/nadezhda/Desktop/Road-Segmentation-ML\n"
               ]
            }
         ],
         "source": [
            "import os\n",
            "\n",
            "if os.getcwd().split(\"/\")[-1] != \"Road-Segmentation-ML\":\n",
            "    os.chdir(\"..\")\n",
            "print(\"CWD:\", os.getcwd())"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 42,
         "metadata": {},
         "outputs": [],
         "source": [
            "import torch\n",
            "from omegaconf import OmegaConf\n",
            "import segmentation_models_pytorch as smp\n",
            "from utils import set_seeds\n",
            "from train_utils import prepare_data, prepare_model, prepare_optimizer, train"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 43,
         "metadata": {},
         "outputs": [],
         "source": [
            "# create folder models if it doesn't exist\n",
            "if not os.path.exists(\"models\"):\n",
            "    os.makedirs(\"models\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 44,
         "metadata": {},
         "outputs": [],
         "source": [
            "args = OmegaConf.create(\n",
            "    dict(\n",
            "        # General\n",
            "        seed=0,\n",
            "        # Data folders\n",
            "        train_image_folders=[\"datasets/train/images/\", \"datasets/massachusetts_384/images/\"], # add Massachusetts here\n",
            "        train_gt_folders=[\"datasets/train/groundtruth/\", \"datasets/massachusetts_384/groundtruth/\"], # add Massachusetts here\n",
            "        val_image_folders=[\"datasets/validation/images/\"], \n",
            "        val_gt_folders=[\"datasets/validation/groundtruth/\"],\n",
            "        weighted_random_sampler=False,\n",
            "        # Data tranforms\n",
            "        # random_resized_crop: crop a random portion of image and resize it to a given size\n",
            "        random_resized_crop=False,\n",
            "        output_size=(400, 400),  # expected output size of the crop, for each edge.\n",
            "        input_size=(384),  # resize\n",
            "        random_resized_crop_scale=(0.5, 0.5),\n",
            "        # random_horizontal_flip: randomly flip the image horizontally with a given probability\n",
            "        random_horizontal_flip=False,\n",
            "        # random_vertical_flip: randomly flip the image vertically with a given probability\n",
            "        random_vertical_flip=False,\n",
            "        # random_rotation: randomly rotate the image with a given probability\n",
            "        random_rotation=False,\n",
            "        degrees=5,  # range of degrees to select from\n",
            "        # color_jitter: randomly change the brightness, contrast and saturation of an image\n",
            "        color_jitter=False,\n",
            "        brightness=0.1,  # how much to jitter brightness.\n",
            "        contrast=0.1,  # how much to jitter contrast.\n",
            "        saturation=0.1,  # how much to jitter saturation.\n",
            "        hue=0.1,  # how much to jitter hue.\n",
            "        # normalization\n",
            "        normalization=True,  # TODO: Should it always be True?\n",
            "        normalization_flag = \"A\", # \"A\" for AIcrowd, \"AM\" for AIcrowd + Massachusetts, \"AK\" for AIcrowd + Kaggle\n",
            "        # Data loaders\n",
            "        batch_size=2,\n",
            "        train_size=0.8,\n",
            "        val_size=0.2,\n",
            "        # Model\n",
            "        # UNetV1\n",
            "        model_name=\"UNetV3\",  # Change for v3\n",
            "        model_save_name=\"models/checkpoints/unetv3-resnet50-normalization-BEST2.pt\",\n",
            "        # Optimizer\n",
            "        optim_name=\"adam\",  # sgd\n",
            "        optim_lr=0.001,\n",
            "        optim_momentum=0.9,  # TODO: Try with (optim_momentum != 0) and without (momentum = 0)?\n",
            "        # Training\n",
            "        n_steps=2000,\n",
            "        eval_freq=100,\n",
            "        # Wandb logging\n",
            "        wandb_project=\"road-segmentation\",\n",
            "        wandb_run=\"unet-v3\",\n",
            "        entity=\"feeit\",\n",
            "    )\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# set seeds\n",
            "set_seeds()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 45,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Using Resize with input size=384.\n",
                  "Using ToTensor.\n",
                  "Using Normalize with mean=[0.358, 0.365, 0.3316] and std=[0.1976, 0.1917, 0.194].\n",
                  "Using WeightedRandomSampler.\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/home/nadezhda/.local/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
                  "  warnings.warn(\n"
               ]
            }
         ],
         "source": [
            "# prepare train and validation loaders\n",
            "train_loader, val_loader = prepare_data(args)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 46,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Initializing UNetV3 model.\n",
                  "Initializing Adam optimizer with lr=0.001.\n"
               ]
            }
         ],
         "source": [
            "# prepare model\n",
            "model = prepare_model(args)\n",
            "# define loss function\n",
            "criterion = torch.nn.BCEWithLogitsLoss()\n",
            "# criterion = DiceLoss()\n",
            "# prepare optimizer\n",
            "optimizer = prepare_optimizer(model, args)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 47,
         "metadata": {},
         "outputs": [],
         "source": [
            "# MODEL_CHECKPOINT = \"models/checkpoints/unetv3-resnet50-normalization-BEST.pt\"\n",
            "# model.load_state_dict(torch.load(MODEL_CHECKPOINT))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 48,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "UNetV3(\n",
                     "  (model): Unet(\n",
                     "    (encoder): ResNetEncoder(\n",
                     "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
                     "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "      (relu): ReLU(inplace=True)\n",
                     "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
                     "      (layer1): Sequential(\n",
                     "        (0): Bottleneck(\n",
                     "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (relu): ReLU(inplace=True)\n",
                     "          (downsample): Sequential(\n",
                     "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          )\n",
                     "        )\n",
                     "        (1): Bottleneck(\n",
                     "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (relu): ReLU(inplace=True)\n",
                     "        )\n",
                     "        (2): Bottleneck(\n",
                     "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (relu): ReLU(inplace=True)\n",
                     "        )\n",
                     "      )\n",
                     "      (layer2): Sequential(\n",
                     "        (0): Bottleneck(\n",
                     "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
                     "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (relu): ReLU(inplace=True)\n",
                     "          (downsample): Sequential(\n",
                     "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
                     "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          )\n",
                     "        )\n",
                     "        (1): Bottleneck(\n",
                     "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (relu): ReLU(inplace=True)\n",
                     "        )\n",
                     "        (2): Bottleneck(\n",
                     "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (relu): ReLU(inplace=True)\n",
                     "        )\n",
                     "        (3): Bottleneck(\n",
                     "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (relu): ReLU(inplace=True)\n",
                     "        )\n",
                     "      )\n",
                     "      (layer3): Sequential(\n",
                     "        (0): Bottleneck(\n",
                     "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
                     "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (relu): ReLU(inplace=True)\n",
                     "          (downsample): Sequential(\n",
                     "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
                     "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          )\n",
                     "        )\n",
                     "        (1): Bottleneck(\n",
                     "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (relu): ReLU(inplace=True)\n",
                     "        )\n",
                     "        (2): Bottleneck(\n",
                     "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (relu): ReLU(inplace=True)\n",
                     "        )\n",
                     "        (3): Bottleneck(\n",
                     "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (relu): ReLU(inplace=True)\n",
                     "        )\n",
                     "        (4): Bottleneck(\n",
                     "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (relu): ReLU(inplace=True)\n",
                     "        )\n",
                     "        (5): Bottleneck(\n",
                     "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (relu): ReLU(inplace=True)\n",
                     "        )\n",
                     "      )\n",
                     "      (layer4): Sequential(\n",
                     "        (0): Bottleneck(\n",
                     "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
                     "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (relu): ReLU(inplace=True)\n",
                     "          (downsample): Sequential(\n",
                     "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
                     "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          )\n",
                     "        )\n",
                     "        (1): Bottleneck(\n",
                     "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (relu): ReLU(inplace=True)\n",
                     "        )\n",
                     "        (2): Bottleneck(\n",
                     "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                     "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "          (relu): ReLU(inplace=True)\n",
                     "        )\n",
                     "      )\n",
                     "    )\n",
                     "    (decoder): UnetDecoder(\n",
                     "      (center): Identity()\n",
                     "      (blocks): ModuleList(\n",
                     "        (0): DecoderBlock(\n",
                     "          (conv1): Conv2dReLU(\n",
                     "            (0): Conv2d(3072, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "            (2): ReLU(inplace=True)\n",
                     "          )\n",
                     "          (attention1): Attention(\n",
                     "            (attention): Identity()\n",
                     "          )\n",
                     "          (conv2): Conv2dReLU(\n",
                     "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "            (2): ReLU(inplace=True)\n",
                     "          )\n",
                     "          (attention2): Attention(\n",
                     "            (attention): Identity()\n",
                     "          )\n",
                     "        )\n",
                     "        (1): DecoderBlock(\n",
                     "          (conv1): Conv2dReLU(\n",
                     "            (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "            (2): ReLU(inplace=True)\n",
                     "          )\n",
                     "          (attention1): Attention(\n",
                     "            (attention): Identity()\n",
                     "          )\n",
                     "          (conv2): Conv2dReLU(\n",
                     "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "            (2): ReLU(inplace=True)\n",
                     "          )\n",
                     "          (attention2): Attention(\n",
                     "            (attention): Identity()\n",
                     "          )\n",
                     "        )\n",
                     "        (2): DecoderBlock(\n",
                     "          (conv1): Conv2dReLU(\n",
                     "            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "            (2): ReLU(inplace=True)\n",
                     "          )\n",
                     "          (attention1): Attention(\n",
                     "            (attention): Identity()\n",
                     "          )\n",
                     "          (conv2): Conv2dReLU(\n",
                     "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "            (2): ReLU(inplace=True)\n",
                     "          )\n",
                     "          (attention2): Attention(\n",
                     "            (attention): Identity()\n",
                     "          )\n",
                     "        )\n",
                     "        (3): DecoderBlock(\n",
                     "          (conv1): Conv2dReLU(\n",
                     "            (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "            (2): ReLU(inplace=True)\n",
                     "          )\n",
                     "          (attention1): Attention(\n",
                     "            (attention): Identity()\n",
                     "          )\n",
                     "          (conv2): Conv2dReLU(\n",
                     "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "            (2): ReLU(inplace=True)\n",
                     "          )\n",
                     "          (attention2): Attention(\n",
                     "            (attention): Identity()\n",
                     "          )\n",
                     "        )\n",
                     "        (4): DecoderBlock(\n",
                     "          (conv1): Conv2dReLU(\n",
                     "            (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "            (2): ReLU(inplace=True)\n",
                     "          )\n",
                     "          (attention1): Attention(\n",
                     "            (attention): Identity()\n",
                     "          )\n",
                     "          (conv2): Conv2dReLU(\n",
                     "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                     "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                     "            (2): ReLU(inplace=True)\n",
                     "          )\n",
                     "          (attention2): Attention(\n",
                     "            (attention): Identity()\n",
                     "          )\n",
                     "        )\n",
                     "      )\n",
                     "    )\n",
                     "    (segmentation_head): SegmentationHead(\n",
                     "      (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
                     "      (1): Identity()\n",
                     "      (2): Activation(\n",
                     "        (activation): Identity()\n",
                     "      )\n",
                     "    )\n",
                     "  )\n",
                     ")"
                  ]
               },
               "execution_count": 48,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# device to use for training\n",
            "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "model.to(device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# train\n",
            "trained_model = train(\n",
            "    model, device, train_loader, val_loader, criterion, optimizer, args\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Submission"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import torch\n",
            "import torchvision.transforms.v2 as transforms\n",
            "import torchvision.models.segmentation as models\n",
            "import matplotlib.pyplot as plt\n",
            "from datasets.TestDataset import TestDataset\n",
            "from models.UNetV3 import UNetV3\n",
            "from examples.mask_to_submission import *"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# select checkpoint\n",
            "MODEL = \"models/checkpoints/unetv3-resnet50-normalization-BEST2.pt\"\n",
            "# load checkpoint\n",
            "try:\n",
            "    checkpoint = torch.load(MODEL)\n",
            "except:\n",
            "    print(\"Loading checkpoint failed. Trying to load it with map_location.\")\n",
            "    checkpoint = torch.load(MODEL, map_location=torch.device(\"cpu\"))\n",
            "# create model\n",
            "model = UNetV3()\n",
            "# load model weights\n",
            "model.load_state_dict(checkpoint)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# path to the test folder\n",
            "test_folder = \"datasets/test/\"\n",
            "\n",
            "# set mean and std\n",
            "mean = [0.3353, 0.3328, 0.2984]\n",
            "std = [0.1967, 0.1896, 0.1897]\n",
            "\n",
            "# define transformations\n",
            "transform = transforms.Compose(\n",
            "    [\n",
            "        transforms.ToTensor(),\n",
            "        transforms.Normalize(mean=mean, std=std),\n",
            "    ]\n",
            ")\n",
            "\n",
            "# create test dataset\n",
            "test_dataset = TestDataset(test_folder, transform=transform)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# set threshold\n",
            "THR = 0.5\n",
            "# create folder predictions if it doesn't exist\n",
            "if not os.path.exists(\"predictions\"):\n",
            "    os.makedirs(\"predictions\")\n",
            "# save predictions\n",
            "prediction_filenames = []\n",
            "for i in range(len(test_dataset)):\n",
            "    # get image\n",
            "    image = test_dataset[i]\n",
            "    # create prediction\n",
            "    prediction = model(image.unsqueeze(0))\n",
            "    # threshold prediction\n",
            "    prediction = torch.sigmoid(prediction)\n",
            "    prediction = (prediction > THR).float()\n",
            "    # save prediction\n",
            "    prediction_filename = \"predictions/prediction_\" + str(i + 1) + \".png\"\n",
            "    prediction_filenames.append(prediction_filename)\n",
            "    plt.imsave(prediction_filename, prediction.squeeze().detach().numpy(), cmap=\"gray\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# create submission\n",
            "masks_to_submission(\"submission.csv\", *prediction_filenames)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.12"
      },
      "vscode": {
         "interpreter": {
            "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
