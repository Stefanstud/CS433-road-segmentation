{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /home/nadezhda/Desktop/Road-Segmentation-ML\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.getcwd().split(\"/\")[-1] != \"Road-Segmentation-ML\":\n",
    "    os.chdir(\"..\")\n",
    "print(\"CWD:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from utils import set_seeds\n",
    "from train_utils import prepare_data, prepare_model, prepare_optimizer, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder models if it doesn't exist\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = OmegaConf.create(\n",
    "    dict(\n",
    "        # General\n",
    "        seed=0,\n",
    "        # Data folders\n",
    "        train_image_folders=[\"datasets/train/images/\"], # add Massachusetts here\n",
    "        train_gt_folders=[\"datasets/train/groundtruth/\"], # add Massachusetts here\n",
    "        val_image_folders=[\"datasets/validation/images/\"], \n",
    "        val_gt_folders=[\"datasets/validation/groundtruth/\"],\n",
    "        weighted_random_sampler=False,\n",
    "        # Data tranforms\n",
    "        # random_resized_crop: crop a random portion of image and resize it to a given size\n",
    "        random_resized_crop=False,\n",
    "        output_size=(400, 400),  # expected output size of the crop, for each edge.\n",
    "        input_size=400,  # size of the original image before random cropping\n",
    "        random_resized_crop_scale=(0.5, 1.0),\n",
    "        # random_horizontal_flip: randomly flip the image horizontally with a given probability\n",
    "        random_horizontal_flip=False,\n",
    "        # random_vertical_flip: randomly flip the image vertically with a given probability\n",
    "        random_vertical_flip=False,\n",
    "        # random_rotation: randomly rotate the image with a given probability\n",
    "        random_rotation=False,\n",
    "        degrees=5,  # range of degrees to select from\n",
    "        # color_jitter: randomly change the brightness, contrast and saturation of an image\n",
    "        color_jitter=False,\n",
    "        brightness=0.1,  # how much to jitter brightness.\n",
    "        contrast=0.1,  # how much to jitter contrast.\n",
    "        saturation=0.1,  # how much to jitter saturation.\n",
    "        hue=0.1,  # how much to jitter hue.\n",
    "        # normalization\n",
    "        normalization=False,  # TODO: Should it always be True?\n",
    "        normalization_flag = \"A\", # \"A\" for AIcrowd, \"AM\" for AIcrowd + Massachusetts, \"AK\" for AIcrowd + Kaggle\n",
    "        # Data loaders\n",
    "        batch_size=2,\n",
    "        train_size=0.8,\n",
    "        val_size=0.2,\n",
    "        # Model\n",
    "        # UNetV1\n",
    "        model_name=\"UNetV1\",\n",
    "        model_pretrained=False,\n",
    "        model_scale=0.5,\n",
    "        model_save_name=\"models/checkpoints/unetv1-1-test.pt\",\n",
    "        # Optimizer\n",
    "        optim_name=\"adam\",  # sgd\n",
    "        optim_lr=0.1,\n",
    "        optim_momentum=0.9,  # TODO: Try with (optim_momentum != 0) and without (momentum = 0)?\n",
    "        # Training\n",
    "        n_steps=2000,\n",
    "        eval_freq=100,\n",
    "        # Wandb logging\n",
    "        wandb_project=\"road-segmentation\",\n",
    "        wandb_run=\"unet-v1\",\n",
    "        entity=\"feeit\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds\n",
    "set_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Resize with input size=400.\n",
      "Using ToTensor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadezhda/.local/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# prepare train and validation loaders\n",
    "train_loader, val_loader = prepare_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing UNetV1 model with pretrained=False, scale=0.5.\n",
      "Initializing Adam optimizer with lr=0.1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/nadezhda/.cache/torch/hub/milesial_Pytorch-UNet_master\n"
     ]
    }
   ],
   "source": [
    "# prepare model\n",
    "model = prepare_model(args)\n",
    "# define loss function\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "# prepare optimizer\n",
    "optimizer = prepare_optimizer(model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetV1(\n",
       "  (model): UNet(\n",
       "    (inc): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down1): Down(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): DoubleConv(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down2): Down(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): DoubleConv(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down3): Down(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): DoubleConv(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down4): Down(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): DoubleConv(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up1): Up(\n",
       "      (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up2): Up(\n",
       "      (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up3): Up(\n",
       "      (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up4): Up(\n",
       "      (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (outc): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device to use for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "trained_model = train(\n",
    "    model, device, train_loader, val_loader, criterion, optimizer, args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torchvision.models.segmentation as models\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets.TestDataset import TestDataset\n",
    "from models.UNetV1 import UNetV1\n",
    "from examples.mask_to_submission import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select checkpoint\n",
    "MODEL = \"models/checkpoints/unetv1-1.pt\"\n",
    "# load checkpoint\n",
    "try:\n",
    "    checkpoint = torch.load(MODEL)\n",
    "except:\n",
    "    print(\"Loading checkpoint failed. Trying to load it with map_location.\")\n",
    "    checkpoint = torch.load(MODEL)\n",
    "# create model\n",
    "model = UNetV1()\n",
    "# load model weights\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the test folder\n",
    "test_folder = \"datasets/test/\"\n",
    "\n",
    "# set mean and std\n",
    "mean = [0.3353, 0.3328, 0.2984]\n",
    "std = [0.1967, 0.1896, 0.1897]\n",
    "\n",
    "# define transformations\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create test dataset\n",
    "test_dataset = TestDataset(test_folder, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set threshold\n",
    "THR = 0.5\n",
    "# create folder predictions if it doesn't exist\n",
    "if not os.path.exists(\"predictions\"):\n",
    "    os.makedirs(\"predictions\")\n",
    "# save predictions\n",
    "prediction_filenames = []\n",
    "for i in range(len(test_dataset)):\n",
    "    # get image\n",
    "    image = test_dataset[i]\n",
    "    # create prediction\n",
    "    prediction = model(image.unsqueeze(0))\n",
    "    # threshold prediction\n",
    "    prediction = torch.sigmoid(prediction)\n",
    "    prediction = (prediction > THR).float()\n",
    "    # save prediction\n",
    "    prediction_filename = \"predictions/prediction_\" + str(i + 1) + \".png\"\n",
    "    prediction_filenames.append(prediction_filename)\n",
    "    plt.imsave(prediction_filename, prediction.squeeze().detach().numpy(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission\n",
    "masks_to_submission(\"submission.csv\", *prediction_filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
