{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getcwd().split(\"/\")[-1] != \"Road-Segmentation-ML\":\n",
    "    os.chdir(\"..\")\n",
    "print(\"CWD:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from utils import set_seeds\n",
    "from train_utils import prepare_data, prepare_model, prepare_optimizer, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder models if it doesn't exist\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = OmegaConf.create(\n",
    "    dict(\n",
    "        # General\n",
    "        seed=0,\n",
    "        # Data folders\n",
    "        train_image_folders=[\n",
    "            \"datasets/train/images/\",\n",
    "            # \"datasets/massachusetts_384/images/\",\n",
    "            # \"datasets/kaggle/images/\",\n",
    "        ],  # add Massachusetts here\n",
    "        train_gt_folders=[\n",
    "            \"datasets/train/groundtruth/\",\n",
    "            # \"datasets/massachusetts_384/groundtruth/\",\n",
    "            # \"datasets/kaggle/groundtruth/\",\n",
    "        ],  # add Massachusetts here\n",
    "        val_image_folders=[\"datasets/validation/images/\"],\n",
    "        val_gt_folders=[\"datasets/validation/groundtruth/\"],\n",
    "        weighted_random_sampler=False,\n",
    "        # Data tranforms\n",
    "        # random_resized_crop: crop a random portion of image and resize it to a given size\n",
    "        random_resized_crop=False,\n",
    "        output_size=(400, 400),  # expected output size of the crop, for each edge.\n",
    "        input_size=(400),  # resize\n",
    "        random_resized_crop_scale=(0.5, 0.5),\n",
    "        # random_horizontal_flip: randomly flip the image horizontally with a given probability\n",
    "        random_horizontal_flip=True,\n",
    "        # random_vertical_flip: randomly flip the image vertically with a given probability\n",
    "        random_vertical_flip=True,\n",
    "        # random_rotation: randomly rotate the image with a given probability\n",
    "        random_rotation=True,\n",
    "        degrees=10,  # range of degrees to select from\n",
    "        # color_jitter: randomly change the brightness, contrast and saturation of an image\n",
    "        color_jitter=False,\n",
    "        brightness=0.1,  # how much to jitter brightness.\n",
    "        contrast=0.1,  # how much to jitter contrast.\n",
    "        saturation=0.1,  # how much to jitter saturation.\n",
    "        hue=0.1,  # how much to jitter hue.\n",
    "        # normalization\n",
    "        normalization=True,  # TODO: Should it always be True?\n",
    "        normalization_flag=\"A\",  # \"A\" for AIcrowd, \"AM\" for AIcrowd + Massachusetts, \"AK\" for AIcrowd + Kaggle\n",
    "        # Data loaders\n",
    "        batch_size=4,\n",
    "        train_size=0.8,\n",
    "        val_size=0.2,\n",
    "        # Model\n",
    "        model_name=\"ResNet50\",\n",
    "        model_pretrained=False,\n",
    "        model_save_name=\"models/checkpoints/deeplabv3_resnet50_HUGE_retrain_2.pt\",\n",
    "        # Optimizer\n",
    "        optim_name=\"adam\",  # sgd\n",
    "        optim_lr=3e-5,\n",
    "        optim_momentum=0.9,  # TODO: Try with (optim_momentum != 0) and without (momentum = 0)?\n",
    "        # Training\n",
    "        n_steps=3000,\n",
    "        eval_freq=100,\n",
    "        # Wandb logging\n",
    "        wandb_project=\"road-segmentation-clahe\",\n",
    "        wandb_run=\"deeplabv3-resnet50\",\n",
    "        entity=\"feeit\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds\n",
    "set_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train and validation loaders\n",
    "train_loader, val_loader = prepare_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model\n",
    "model = prepare_model(args)\n",
    "# define loss function\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "# prepare optimizer\n",
    "optimizer = prepare_optimizer(model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"models/checkpoints/deeplabv3_resnet50_HUGE.pt\"\n",
    "model.load_state_dict(torch.load(MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device to use for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "trained_model = train(\n",
    "    model, device, train_loader, val_loader, criterion, optimizer, args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torchvision.models.segmentation as models\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets.TestDataset import TestDataset\n",
    "from models.DeepLabV3 import ResNet50\n",
    "from examples.mask_to_submission import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select checkpoint\n",
    "MODEL = \"models/checkpoints/deeplabv3_resnet50_HUGE_retrain.pt\"\n",
    "# load checkpoint\n",
    "try:\n",
    "    checkpoint = torch.load(MODEL)\n",
    "except:\n",
    "    print(\"Loading checkpoint failed. Trying to load it with map_location.\")\n",
    "    checkpoint = torch.load(MODEL, map_location=torch.device(\"cpu\"))\n",
    "# create model\n",
    "model = ResNet50()\n",
    "# load model weights\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the test folder\n",
    "test_folder = \"datasets/ethics/\"\n",
    "\n",
    "# set mean and std\n",
    "mean = [0.3353, 0.3328, 0.2984]\n",
    "std = [0.1967, 0.1896, 0.1897]\n",
    "mean = [0.5616, 0.4848, 0.4514]\n",
    "std = [0.1882, 0.1744, 0.1598]\n",
    "# define transformations\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((608, 608)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create test dataset\n",
    "test_dataset = TestDataset(test_folder, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from postprocessing import (\n",
    "    apply_morphological_operations,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "# set threshold\n",
    "THR = 0.6\n",
    "# create folder predictions if it doesn't exist\n",
    "if not os.path.exists(\"predictions\"):\n",
    "    os.makedirs(\"predictions\")\n",
    "# save predictions\n",
    "prediction_filenames = []\n",
    "for i in range(len(test_dataset)):\n",
    "    # get image\n",
    "    image = test_dataset[i]\n",
    "    # create prediction\n",
    "    prediction = model(image.unsqueeze(0))\n",
    "    # threshold prediction\n",
    "    prediction = torch.sigmoid(prediction)\n",
    "    # prediction = (prediction > THR).float()\n",
    "    prediction = prediction.squeeze().detach().numpy()\n",
    "    # apply morphological operations\n",
    "    # prediction = apply_morphological_operations(prediction)\n",
    "    # prediction = (prediction > THR).astype(int)\n",
    "    # save prediction\n",
    "    prediction_filename = \"postprocess/prediction_\" + str(i + 1) + \".png\"\n",
    "    prediction_filenames.append(prediction_filename)\n",
    "    # upscale with bilinear interpolation to 608x608\n",
    "    plt.imsave(prediction_filename, prediction.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission\n",
    "masks_to_submission(\"submission.csv\", *prediction_filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
